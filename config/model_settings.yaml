# Model configuration settings

provider: "ollama"
model: "mistral"

# Model settings - uncomment the ones you want to use
model_kwargs:
  temperature: 0.7
  max_tokens: 1000
  # OpenAI specific options
  # presence_penalty: 0.0
  # frequency_penalty: 0.0
  # Ollama specific options
  num_predict: 1000